{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-fifth",
   "metadata": {},
   "source": [
    "# Bin analaysis\n",
    "\n",
    "Notebook for analyzing the bin division on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spread-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reported-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "ets = np.arange(5)\n",
    "etas = np.arange(5)\n",
    "dataset = 'data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97'\n",
    "new_dataset = 'extra_bins_' + dataset\n",
    "homepath = os.path.expanduser('~')\n",
    "datapath = os.path.join(homepath, 'data', dataset)\n",
    "filepath = os.path.join(datapath, dataset + '_et{et}_eta{eta}.npz')\n",
    "output_dir = os.path.join(datapath, 'bin_analysis')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "outpath = os.path.join(output_dir, 'et{et}_eta{eta}_statiscs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intermediate-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At et: 0 eta: 0\n",
      "At et: 0 eta: 1\n",
      "At et: 0 eta: 2\n",
      "At et: 0 eta: 3\n",
      "At et: 0 eta: 4\n",
      "At et: 1 eta: 0\n",
      "At et: 1 eta: 1\n",
      "At et: 1 eta: 2\n",
      "At et: 1 eta: 3\n",
      "At et: 1 eta: 4\n",
      "At et: 2 eta: 0\n",
      "At et: 2 eta: 1\n",
      "At et: 2 eta: 2\n",
      "At et: 2 eta: 3\n",
      "At et: 2 eta: 4\n",
      "At et: 3 eta: 0\n",
      "At et: 3 eta: 1\n",
      "At et: 3 eta: 2\n",
      "At et: 3 eta: 3\n",
      "At et: 3 eta: 4\n",
      "At et: 4 eta: 0\n",
      "At et: 4 eta: 1\n",
      "At et: 4 eta: 2\n",
      "At et: 4 eta: 3\n",
      "At et: 4 eta: 4\n"
     ]
    }
   ],
   "source": [
    "dfs = [[None for _ in etas] for _ in ets]\n",
    "for et, eta in product(ets, etas):\n",
    "    df_data = list()\n",
    "    json_data = dict.fromkeys(['et', 'eta'])\n",
    "    filepath.format(et=0, eta=0)\n",
    "    print(f'At et: {et} eta: {eta}')\n",
    "    data = dict(np.load(filepath.format(et=et, eta=eta)))\n",
    "    et_index = np.where(data['features'] == 'et')[0][0]\n",
    "    et_values = np.unique(data['data'][:, et_index])\n",
    "    min_et = et_values.min()\n",
    "    max_et = et_values.max()\n",
    "    df_data.append([min_et, max_et])\n",
    "    json_data['et'] = {\n",
    "        'min': float(min_et),\n",
    "        'max': float(max_et)\n",
    "        #'unique': [float(val) for val in et_values]\n",
    "    }\n",
    "    \n",
    "    eta_index = np.where(data['features'] == 'eta')[0][0]\n",
    "    eta_values = np.unique(np.abs(data['data'][:, eta_index]))\n",
    "    min_eta = eta_values.min()\n",
    "    max_eta = eta_values.max()\n",
    "    df_data.append([min_eta, max_eta])\n",
    "    json_data['eta'] = {\n",
    "        'min': float(min_eta),\n",
    "        'max': float(max_eta) #,\n",
    "        #'unique': [float(val) for val in eta_values]\n",
    "    }\n",
    "    \n",
    "    targets, counts = np.unique(data['target'], return_counts=True)\n",
    "    json_data['target_count'] = {int(target) : int(count)\n",
    "        for target, count in zip(targets, counts)}\n",
    "    \n",
    "    \n",
    "    dfs[et][eta] = pd.DataFrame(df_data, columns=['min', 'max'], index=['et', 'eta'])\n",
    "    with open(outpath.format(et=et, eta=eta), 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "    \n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b9d21b-ab82-40e9-bd06-b835702ffa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ets = np.arange(5)\n",
    "etas = np.arange(5)\n",
    "dataset = 'mc16_13TeV.302236_309995_341330.sgn.boosted_probes.WZ_llqq_plus_radion_ZZ_llqq_plus_ggH3000.merge.25bins.v2'\n",
    "new_dataset = 'extra_bins_' + dataset\n",
    "homepath = os.path.expanduser('~')\n",
    "datapath = os.path.join(homepath, 'data', dataset)\n",
    "filepath = os.path.join(datapath, dataset + '_et{et}_eta{eta}.npz')\n",
    "output_dir = os.path.join(datapath, 'bin_analysis')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "outpath = os.path.join(output_dir, 'et{et}_eta{eta}_statiscs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "010297d2-aca5-4b1f-a263-73125860ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At et: 0 eta: 0\n",
      "At et: 0 eta: 1\n",
      "At et: 0 eta: 2\n",
      "At et: 0 eta: 3\n",
      "At et: 0 eta: 4\n",
      "At et: 1 eta: 0\n",
      "At et: 1 eta: 1\n",
      "At et: 1 eta: 2\n",
      "At et: 1 eta: 3\n",
      "At et: 1 eta: 4\n",
      "At et: 2 eta: 0\n",
      "At et: 2 eta: 1\n",
      "At et: 2 eta: 2\n",
      "At et: 2 eta: 3\n",
      "At et: 2 eta: 4\n",
      "At et: 3 eta: 0\n",
      "At et: 3 eta: 1\n",
      "At et: 3 eta: 2\n",
      "At et: 3 eta: 3\n",
      "At et: 3 eta: 4\n",
      "At et: 4 eta: 0\n",
      "At et: 4 eta: 1\n",
      "At et: 4 eta: 2\n",
      "At et: 4 eta: 3\n",
      "At et: 4 eta: 4\n"
     ]
    }
   ],
   "source": [
    "dfs = [[None for _ in etas] for _ in ets]\n",
    "for et, eta in product(ets, etas):\n",
    "    df_data = list()\n",
    "    json_data = dict.fromkeys(['et', 'eta'])\n",
    "    filepath.format(et=0, eta=0)\n",
    "    print(f'At et: {et} eta: {eta}')\n",
    "    data = dict(np.load(filepath.format(et=et, eta=eta)))\n",
    "    et_index = np.where(data['features_float'] == 'el_et')[0][0]\n",
    "    et_values = np.unique(data['data_float'][:, et_index])\n",
    "    min_et = et_values.min()\n",
    "    max_et = et_values.max()\n",
    "    df_data.append([min_et, max_et])\n",
    "    json_data['et'] = {\n",
    "        'min': float(min_et),\n",
    "        'max': float(max_et)\n",
    "        #'unique': [float(val) for val in et_values]\n",
    "    }\n",
    "    \n",
    "    eta_index = np.where(data['features_float'] == 'el_eta')[0][0]\n",
    "    eta_values = np.unique(np.abs(data['data_float'][:, eta_index]))\n",
    "    min_eta = eta_values.min()\n",
    "    max_eta = eta_values.max()\n",
    "    df_data.append([min_eta, max_eta])\n",
    "    json_data['eta'] = {\n",
    "        'min': float(min_eta),\n",
    "        'max': float(max_eta) #,\n",
    "        #'unique': [float(val) for val in eta_values]\n",
    "    }\n",
    "    \n",
    "    targets, counts = np.unique(data['target'], return_counts=True)\n",
    "    json_data['target_count'] = {int(target) : int(count)\n",
    "        for target, count in zip(targets, counts)}\n",
    "    \n",
    "    \n",
    "    dfs[et][eta] = pd.DataFrame(df_data, columns=['min', 'max'], index=['et', 'eta'])\n",
    "    with open(outpath.format(et=et, eta=eta), 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "    \n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afraid-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join(homepath, 'data', 'data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins')\n",
    "filepath = os.path.join(datapath, 'data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et{et}_eta{eta}.npz')\n",
    "data = dict(np.load(filepath.format(et=0, eta=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "everyday-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['etBins', 'etaBins', 'etBinIdx', 'etaBinIdx', 'ordered_features', 'data_float', 'data_bool', 'data_int', 'data_object', 'features_float', 'features_bool', 'features_int', 'features_object', 'target', 'protocol', 'allow_pickle'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thick-announcement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el_et'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_index = np.where(data['features_float'] == 'el_et')[0][0]\n",
    "et_values = np.unique(data['data_float'][:,et_index])\n",
    "data['features_float'][et_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "broken-index",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443444,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pediatric-slave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2606.5542, 622928.2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_values.min(), et_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "heated-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el_eta'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta_index = np.where(data['features_float'] == 'el_eta')[0][0]\n",
    "eta_values = np.abs(np.unique(data['data_float'][:,eta_index]))\n",
    "data['features_float'][eta_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "listed-failure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.221265e-06, 1.0581734)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta_values.min(), eta_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "231ffe6f-5a8e-48d0-a0d8-23da705f06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join(homepath, 'data', 'mc16_13TeV.302236_309995_341330.sgn.boosted_probes.WZ_llqq_plus_radion_ZZ_llqq_plus_ggH3000.merge.25bins.v2')\n",
    "filepath = os.path.join(datapath, 'mc16_13TeV.302236_309995_341330.sgn.boosted_probes.WZ_llqq_plus_radion_ZZ_llqq_plus_ggH3000.merge.25bins.v2_et{et}_eta{eta}.npz')\n",
    "data = dict(np.load(filepath.format(et=0, eta=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c191048-82ce-4b5e-9254-04ee86f2ecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['etBins', 'etaBins', 'etBinIdx', 'etaBinIdx', 'ordered_features', 'data_float', 'data_bool', 'data_int', 'data_object', 'features_float', 'features_bool', 'features_int', 'features_object', 'target', 'protocol', 'allow_pickle'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
