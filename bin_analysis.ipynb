{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-fifth",
   "metadata": {},
   "source": [
    "# Bin analaysis\n",
    "\n",
    "Notebook for analyzing the bin division on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spread-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reported-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "ets = np.arange(5)\n",
    "etas = np.arange(5)\n",
    "dataset = 'data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97'\n",
    "new_dataset = 'extra_bins_' + dataset\n",
    "homepath = os.path.expanduser('~')\n",
    "datapath = os.path.join(homepath, 'data', dataset)\n",
    "filepath = os.path.join(datapath, dataset + '_et{et}_eta{eta}.npz')\n",
    "output_dir = os.path.join(datapath, 'bin_analysis')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "outpath = os.path.join(output_dir, 'et{et}_eta{eta}_statiscs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632e32b0-596d-48cf-bf1a-eb5ae3b07e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(np.load(filepath.format(et=0, eta=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181635a5-9309-4151-9c6d-516bdc0ccf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['avgmu', 'L2Calo_ring_0', 'L2Calo_ring_1', 'L2Calo_ring_2',\n",
       "       'L2Calo_ring_3', 'L2Calo_ring_4', 'L2Calo_ring_5', 'L2Calo_ring_6',\n",
       "       'L2Calo_ring_7', 'L2Calo_ring_8', 'L2Calo_ring_9',\n",
       "       'L2Calo_ring_10', 'L2Calo_ring_11', 'L2Calo_ring_12',\n",
       "       'L2Calo_ring_13', 'L2Calo_ring_14', 'L2Calo_ring_15',\n",
       "       'L2Calo_ring_16', 'L2Calo_ring_17', 'L2Calo_ring_18',\n",
       "       'L2Calo_ring_19', 'L2Calo_ring_20', 'L2Calo_ring_21',\n",
       "       'L2Calo_ring_22', 'L2Calo_ring_23', 'L2Calo_ring_24',\n",
       "       'L2Calo_ring_25', 'L2Calo_ring_26', 'L2Calo_ring_27',\n",
       "       'L2Calo_ring_28', 'L2Calo_ring_29', 'L2Calo_ring_30',\n",
       "       'L2Calo_ring_31', 'L2Calo_ring_32', 'L2Calo_ring_33',\n",
       "       'L2Calo_ring_34', 'L2Calo_ring_35', 'L2Calo_ring_36',\n",
       "       'L2Calo_ring_37', 'L2Calo_ring_38', 'L2Calo_ring_39',\n",
       "       'L2Calo_ring_40', 'L2Calo_ring_41', 'L2Calo_ring_42',\n",
       "       'L2Calo_ring_43', 'L2Calo_ring_44', 'L2Calo_ring_45',\n",
       "       'L2Calo_ring_46', 'L2Calo_ring_47', 'L2Calo_ring_48',\n",
       "       'L2Calo_ring_49', 'L2Calo_ring_50', 'L2Calo_ring_51',\n",
       "       'L2Calo_ring_52', 'L2Calo_ring_53', 'L2Calo_ring_54',\n",
       "       'L2Calo_ring_55', 'L2Calo_ring_56', 'L2Calo_ring_57',\n",
       "       'L2Calo_ring_58', 'L2Calo_ring_59', 'L2Calo_ring_60',\n",
       "       'L2Calo_ring_61', 'L2Calo_ring_62', 'L2Calo_ring_63',\n",
       "       'L2Calo_ring_64', 'L2Calo_ring_65', 'L2Calo_ring_66',\n",
       "       'L2Calo_ring_67', 'L2Calo_ring_68', 'L2Calo_ring_69',\n",
       "       'L2Calo_ring_70', 'L2Calo_ring_71', 'L2Calo_ring_72',\n",
       "       'L2Calo_ring_73', 'L2Calo_ring_74', 'L2Calo_ring_75',\n",
       "       'L2Calo_ring_76', 'L2Calo_ring_77', 'L2Calo_ring_78',\n",
       "       'L2Calo_ring_79', 'L2Calo_ring_80', 'L2Calo_ring_81',\n",
       "       'L2Calo_ring_82', 'L2Calo_ring_83', 'L2Calo_ring_84',\n",
       "       'L2Calo_ring_85', 'L2Calo_ring_86', 'L2Calo_ring_87',\n",
       "       'L2Calo_ring_88', 'L2Calo_ring_89', 'L2Calo_ring_90',\n",
       "       'L2Calo_ring_91', 'L2Calo_ring_92', 'L2Calo_ring_93',\n",
       "       'L2Calo_ring_94', 'L2Calo_ring_95', 'L2Calo_ring_96',\n",
       "       'L2Calo_ring_97', 'L2Calo_ring_98', 'L2Calo_ring_99', 'L2Calo_et',\n",
       "       'L2Calo_eta', 'L2Calo_phi', 'L2Calo_reta', 'L2Calo_ehad1',\n",
       "       'L2Calo_eratio', 'L2Calo_f1', 'L2Calo_f3', 'L2Calo_weta2',\n",
       "       'L2Calo_wstot', 'L2Calo_e2tsts1', 'L2Electron_hastrack',\n",
       "       'L2Electron_pt', 'L2Electron_eta', 'L2Electron_phi',\n",
       "       'L2Electron_caloEta', 'L2Electron_trkClusDeta',\n",
       "       'L2Electron_trkClusDphi', 'L2Electron_etOverPt', 'et', 'eta',\n",
       "       'phi', 'rhad1', 'rhad', 'f3', 'weta2', 'rphi', 'reta', 'wtots1',\n",
       "       'eratio', 'f1', 'hastrack', 'numberOfBLayerHits',\n",
       "       'numberOfPixelHits', 'numberOfTRTHits', 'd0', 'd0significance',\n",
       "       'eProbabilityHT', 'trans_TRT_PID', 'deltaEta1', 'deltaPhi2',\n",
       "       'deltaPhi2Rescaled', 'DeltaPOverP', 'deltaR', 'eeMass',\n",
       "       'el_lhtight', 'el_lhmedium', 'el_lhloose', 'el_lhvloose',\n",
       "       'T0HLTElectronT2CaloTight', 'T0HLTElectronT2CaloMedium',\n",
       "       'T0HLTElectronT2CaloLoose', 'T0HLTElectronT2CaloVLoose'],\n",
       "      dtype='<U25')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intermediate-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At et: 0 eta: 0\n",
      "At et: 0 eta: 1\n",
      "At et: 0 eta: 2\n",
      "At et: 0 eta: 3\n",
      "At et: 0 eta: 4\n",
      "At et: 1 eta: 0\n",
      "At et: 1 eta: 1\n",
      "At et: 1 eta: 2\n",
      "At et: 1 eta: 3\n",
      "At et: 1 eta: 4\n",
      "At et: 2 eta: 0\n",
      "At et: 2 eta: 1\n",
      "At et: 2 eta: 2\n",
      "At et: 2 eta: 3\n",
      "At et: 2 eta: 4\n",
      "At et: 3 eta: 0\n",
      "At et: 3 eta: 1\n",
      "At et: 3 eta: 2\n",
      "At et: 3 eta: 3\n",
      "At et: 3 eta: 4\n",
      "At et: 4 eta: 0\n",
      "At et: 4 eta: 1\n",
      "At et: 4 eta: 2\n",
      "At et: 4 eta: 3\n",
      "At et: 4 eta: 4\n"
     ]
    }
   ],
   "source": [
    "dfs = [[None for _ in etas] for _ in ets]\n",
    "for et, eta in product(ets, etas):\n",
    "    df_data = list()\n",
    "    json_data = dict.fromkeys(['et', 'eta'])\n",
    "    filepath.format(et=0, eta=0)\n",
    "    print(f'At et: {et} eta: {eta}')\n",
    "    data = dict(np.load(filepath.format(et=et, eta=eta)))\n",
    "    et_index = np.where(data['features'] == 'L2Calo_et')[0][0]\n",
    "    et_values = np.unique(data['data'][:, et_index])\n",
    "    min_et = et_values.min()\n",
    "    max_et = et_values.max()\n",
    "    df_data.append([min_et, max_et])\n",
    "    json_data['et'] = {\n",
    "        'min': float(min_et),\n",
    "        'max': float(max_et)\n",
    "        #'unique': [float(val) for val in et_values]\n",
    "    }\n",
    "    \n",
    "    eta_index = np.where(data['features'] == 'L2Calo_eta')[0][0]\n",
    "    eta_values = np.unique(np.abs(data['data'][:, eta_index]))\n",
    "    min_eta = eta_values.min()\n",
    "    max_eta = eta_values.max()\n",
    "    df_data.append([min_eta, max_eta])\n",
    "    json_data['eta'] = {\n",
    "        'min': float(min_eta),\n",
    "        'max': float(max_eta) #,\n",
    "        #'unique': [float(val) for val in eta_values]\n",
    "    }\n",
    "    \n",
    "    targets, counts = np.unique(data['target'], return_counts=True)\n",
    "    json_data['target_count'] = {int(target) : int(count)\n",
    "        for target, count in zip(targets, counts)}\n",
    "    \n",
    "    \n",
    "    dfs[et][eta] = pd.DataFrame(df_data, columns=['min', 'max'], index=['et', 'eta'])\n",
    "    with open(outpath.format(et=et, eta=eta), 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "    \n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b9d21b-ab82-40e9-bd06-b835702ffa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ets = np.arange(5)\n",
    "etas = np.arange(5)\n",
    "dataset = 'mc16_13TeV.302236_309995_341330.sgn.boosted_probes.WZ_llqq_plus_radion_ZZ_llqq_plus_ggH3000.merge.25bins.v2'\n",
    "new_dataset = 'extra_bins_' + dataset\n",
    "homepath = os.path.expanduser('~')\n",
    "datapath = os.path.join(homepath, 'data', dataset)\n",
    "filepath = os.path.join(datapath, dataset + '_et{et}_eta{eta}.npz')\n",
    "output_dir = os.path.join(datapath, 'bin_analysis')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "outpath = os.path.join(output_dir, 'et{et}_eta{eta}_statiscs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "010297d2-aca5-4b1f-a263-73125860ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At et: 0 eta: 0\n",
      "At et: 0 eta: 1\n",
      "At et: 0 eta: 2\n",
      "At et: 0 eta: 3\n",
      "At et: 0 eta: 4\n",
      "At et: 1 eta: 0\n",
      "At et: 1 eta: 1\n",
      "At et: 1 eta: 2\n",
      "At et: 1 eta: 3\n",
      "At et: 1 eta: 4\n",
      "At et: 2 eta: 0\n",
      "At et: 2 eta: 1\n",
      "At et: 2 eta: 2\n",
      "At et: 2 eta: 3\n",
      "At et: 2 eta: 4\n",
      "At et: 3 eta: 0\n",
      "At et: 3 eta: 1\n",
      "At et: 3 eta: 2\n",
      "At et: 3 eta: 3\n",
      "At et: 3 eta: 4\n",
      "At et: 4 eta: 0\n",
      "At et: 4 eta: 1\n",
      "At et: 4 eta: 2\n",
      "At et: 4 eta: 3\n",
      "At et: 4 eta: 4\n"
     ]
    }
   ],
   "source": [
    "dfs = [[None for _ in etas] for _ in ets]\n",
    "for et, eta in product(ets, etas):\n",
    "    df_data = list()\n",
    "    json_data = dict.fromkeys(['et', 'eta'])\n",
    "    filepath.format(et=0, eta=0)\n",
    "    print(f'At et: {et} eta: {eta}')\n",
    "    data = dict(np.load(filepath.format(et=et, eta=eta)))\n",
    "    et_index = np.where(data['features_float'] == 'el_et')[0][0]\n",
    "    et_values = np.unique(data['data_float'][:, et_index])\n",
    "    min_et = et_values.min()\n",
    "    max_et = et_values.max()\n",
    "    df_data.append([min_et, max_et])\n",
    "    json_data['et'] = {\n",
    "        'min': float(min_et),\n",
    "        'max': float(max_et)\n",
    "        #'unique': [float(val) for val in et_values]\n",
    "    }\n",
    "    \n",
    "    eta_index = np.where(data['features_float'] == 'el_eta')[0][0]\n",
    "    eta_values = np.unique(np.abs(data['data_float'][:, eta_index]))\n",
    "    min_eta = eta_values.min()\n",
    "    max_eta = eta_values.max()\n",
    "    df_data.append([min_eta, max_eta])\n",
    "    json_data['eta'] = {\n",
    "        'min': float(min_eta),\n",
    "        'max': float(max_eta) #,\n",
    "        #'unique': [float(val) for val in eta_values]\n",
    "    }\n",
    "    \n",
    "    targets, counts = np.unique(data['target'], return_counts=True)\n",
    "    json_data['target_count'] = {int(target) : int(count)\n",
    "        for target, count in zip(targets, counts)}\n",
    "    \n",
    "    \n",
    "    dfs[et][eta] = pd.DataFrame(df_data, columns=['min', 'max'], index=['et', 'eta'])\n",
    "    with open(outpath.format(et=et, eta=eta), 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "    \n",
    "    del data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
